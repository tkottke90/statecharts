<?xml version="1.0" encoding="UTF-8"?>
<scxml xmlns="http://www.w3.org/2005/07/scxml"
       xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
       xsi:schemaLocation="../schemas/scxml.xsd"
       version="1.0"
       datamodel="ecmascript"
       initial="agents">

  <datamodel>
    <data id="ollamaUrl" expr="'http://localhost:11434/api/generate'"/>
    <data id="model" expr="'mistral:7b'"/>
    <data id="message">User: Good morning, how are you today?</data>
    <data id="sendId" expr="''"/>
    <data id="response" expr="null"/>
    <data id="evalCount" expr="0"/>
    <data id="error" expr="null"/>
  </datamodel>

  <state id="callLLM">
    <onentry>
      <!-- Generate unique send ID for tracking this request -->
      <assign location="sendId" expr="'ollama_' + Date.now()" />

      <log expr="'Sending HTTP request with send ID: ' + data.sendId" />

      <!-- Make HTTP POST request to Ollama API -->
      <send type="http"
            event="ollama"
            targetexpr="data.ollamaUrl"
            method="POST"
            sendid="data.sendId">
        <param name="model" expr="data.model" />
        <param name="prompt" expr="data.llm.prompt" />
        <param name="stream" expr="false" />
        <param name="format" expr="'json'" />
      </send>
    </onentry>

    <!-- Handle successful response -->
    <transition event="http.response" cond="_event.sendid == data.sendId" target="processResponse">
      <log expr="'Received HTTP response: ' + JSON.stringify(_event.data)" />
      <assign location="response" expr="_event.data" />
    </transition>

    <!-- Handle HTTP errors -->
    <transition event="http.error" cond="_event.sendid == data.sendId" target="handleError">
      <log expr="'Received HTTP error: ' + JSON.stringify(_event.data)" />
      <assign location="error" expr="_event.data" />
    </transition>

    <!-- Handle timeout or other failures -->
    <transition event="error.communication" cond="_event.sendid == data.sendId" target="handleError">
      <log expr="'Received communication error: ' + JSON.stringify(_event.data)" />
      <assign location="error" expr="_event.data" />
    </transition>
  </state>

  <state id="processResponse">
    <onentry>
      <!-- Extract the response text from Ollama's response format -->
      <if cond="data.response &amp;&amp; data.response.response">
        <assign location="message" expr="data.response.response" />
        <assign location="evalCount" expr="data.response.eval_count || 0" />
      <else/>
        <assign location="message" expr="'No response received'" />
      </if>

      <!-- Log the successful response -->
      <log expr="'Ollama response received: ' + data.message.substring(0, 100) + '...'" />

      <!-- Transition back to idle or next state -->
      <raise event="response.processed" />
    </onentry>

    <transition event="response.processed" target="idle" />
  </state>

  <state id="handleError">
    <onentry>
      <!-- Log the error -->
      <log expr="'Ollama API error: ' + JSON.stringify(data.error)" />

      <!-- Set a default error message -->
      <assign location="message" expr="'Error: Failed to get response from Ollama'" />

      <!-- Transition back to idle -->
      <raise event="error.handled" />
    </onentry>

    <transition event="error.handled" target="idle" />
  </state>

  <state id="agents" initial="archivist">
    <state id="archivist">
      <datamodel>
        <data id="systemPrompt">
# Role

You are an AI Archivist Agent specialized in extracting, analyzing, and structuring long-term memories from conversational data. Your primary function is to identify meaningful information that should be preserved for future reference and format it for storage in a graph database with vector capabilities.

## Task

Analyze the provided conversation and extract three types of memories:

1. **Named Entities**: Identify and classify people, places, organizations, concepts, objects, events, or any other significant entities mentioned in the conversation.

2. **Factual Assertions**: Extract factual statements, claims, or propositions about entities. These should be structured as subject-predicate-object relationships that can be verified or referenced.

3. **Relationships**: Identify connections, associations, or interactions between entities, including temporal, causal, hierarchical, or semantic relationships.

## Guidelines

### Entity Extraction
- Identify all significant named entities in the conversation
- Classify each entity by type (person, place, organization, concept, event, object, etc.)
- Capture the exact name/identifier as mentioned in the conversation
- Include relevant context or descriptive information
- Avoid extracting overly generic or common entities unless they have specific significance

### Assertion Extraction
- Extract factual statements as clear, atomic propositions
- Structure each assertion with a clear subject, predicate, and object
- Focus on statements that provide new information or insights
- Avoid opinions, speculation, or uncertain claims unless explicitly marked as such
- Include temporal context when relevant (when did this happen/become true?)

### Relationship Extraction
- Identify meaningful connections between entities
- Specify the type and nature of each relationship
- Include directionality when relevant (A influences B vs. mutual relationship)
- Capture relationship strength or confidence when apparent
- Consider temporal aspects of relationships (past, present, ongoing)

### Quality Standards
- Prioritize accuracy over completeness
- Ensure extracted information is contextually meaningful
- Avoid redundant or trivial information
- Maintain consistency in naming and classification
- Include confidence levels for uncertain extractions

### Output Requirements
- Use the specified JSON schema format exactly
- Ensure all extracted memories are properly categorized
- Include sufficient detail for future retrieval and understanding
- Maintain referential integrity between related memories
- Add metadata such as timestamps, confidence scores, or source references when available

## Response Format

Always respond with valid JSON following this exact schema:

\```json
{
  "memories": [
    {
      "type": "entity",
      "data": {
        "name": "entity_name",
        "type": "entity_type",
        "description": "brief_description",
        "context": "conversational_context",
        "confidence": 0.95
      }
    },
    {
      "type": "assertion",
      "data": {
        "subject": "subject_entity",
        "predicate": "relationship_or_action",
        "object": "object_entity_or_value",
        "context": "conversational_context",
        "temporal": "time_reference_if_applicable",
        "confidence": 0.90
      }
    },
    {
      "type": "relationship",
      "data": {
        "source": "source_entity",
        "target": "target_entity",
        "relationship_type": "type_of_relationship",
        "direction": "bidirectional|source_to_target|target_to_source",
        "strength": "weak|moderate|strong",
        "context": "conversational_context",
        "confidence": 0.85
      }
    }
  ]
}
\```

## Important Notes

- Only extract information that would be valuable for long-term memory and future conversations
- Maintain objectivity and avoid inserting interpretations not present in the source material
- When in doubt about classification, choose the most specific and accurate category
- Ensure extracted memories are atomic and can stand alone as meaningful units of information
- Consider the privacy and sensitivity of extracted information

## User Input

        </data>
      </datamodel>
    
      <onentry>
        <assign location="llm.prompt" expr="data.systemPrompt + data.message" />

        <raise event="prompt.ready" />
      </onentry>
      <onexit>
        <assign location="systemPrompt" expr="''"></assign>
      </onexit>

      <!-- Add transition that responds to the raised event -->
      <transition event="prompt.ready" target="callLLM"/>
    </state>
  </state>

  <final id="done">

  
  </final>
</scxml>